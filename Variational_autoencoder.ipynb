{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Variational_autoencoder.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO1zx1M6xZHGpExSZT3aqHv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hardiksiloiya/GANs/blob/main/Variational_autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rw5QjcxeZgn6"
      },
      "source": [
        "import keras\n",
        "from keras.layers import Input,Conv2DTranspose,Conv2D,BatchNormalization,LeakyReLU,Dropout,Flatten,Lambda,Dense,Reshape,Activation\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRIQgOkQqJB6"
      },
      "source": [
        "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
        "x_train=x_train.reshape(60000,28,28,1)\n",
        "x_test=x_test.reshape(10000,28,28,1)\n",
        "x_train = x_train.astype(np.float32)\n",
        "y_train = y_train.astype(np.float32)\n",
        "x_test=x_test.astype(np.float32)\n",
        "y_test=y_test.astype(np.float32)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjZPyVO8albw"
      },
      "source": [
        "def func(inp):\n",
        "  u,log_var=inp\n",
        "  epsilon = K.random_normal(shape=K.shape(u), mean=0., stddev=1.)\n",
        "  return u+K.exp(log_var/2)*epsilon\n",
        "\n",
        "encoder_input=Input((28,28,1))\n",
        "x=encoder_input\n",
        "x=Conv2D(filters=32,kernel_size=3,strides=1,padding='same')(x)\n",
        "x=BatchNormalization()(x)\n",
        "x=Dropout(rate=0.25)(x)\n",
        "x=LeakyReLU()(x)\n",
        "x=Conv2D(filters=32,kernel_size=3,strides=2,padding='same')(x)\n",
        "x=BatchNormalization()(x)\n",
        "x=Dropout(rate=0.25)(x)\n",
        "x=LeakyReLU()(x)\n",
        "x=Conv2D(filters=16,kernel_size=3,strides=2,padding='same')(x)\n",
        "x=BatchNormalization()(x)\n",
        "x=Dropout(rate=0.25)(x)\n",
        "x=LeakyReLU()(x)\n",
        "x=Conv2D(filters=16,kernel_size=3,strides=1,padding='same')(x)\n",
        "x=BatchNormalization()(x)\n",
        "x=Dropout(rate=0.25)(x)\n",
        "x=LeakyReLU()(x)\n",
        "x=Flatten()(x)\n",
        "u=Dense(2)(x)\n",
        "log_var=Dense(2)(x)\n",
        "\n",
        "encoder_out=Lambda(func)([u,log_var])    #sampling layer\n",
        "en_model=Model(encoder_input,encoder_out)\n",
        "#en_model.summary()\n"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRr3U0xwj3IR"
      },
      "source": [
        "decoder_input=Input(2)\n",
        "y=Dense(1568)(decoder_input)\n",
        "y=Reshape((7,7,32))(y)\n",
        "y=Conv2DTranspose(filters=10,kernel_size=3,strides=2,padding='same')(y)\n",
        "y=BatchNormalization()(y)\n",
        "y=Dropout(rate=0.25)(y)\n",
        "y=LeakyReLU()(y)\n",
        "y=Conv2DTranspose(filters=10,kernel_size=3,strides=2,padding='same')(y)\n",
        "y=BatchNormalization()(y)\n",
        "y=Dropout(rate=0.25)(y)\n",
        "y=LeakyReLU()(y)\n",
        "y=Conv2DTranspose(filters=10,kernel_size=3,strides=1,padding='same')(y)\n",
        "y=BatchNormalization()(y)\n",
        "y=Dropout(rate=0.25)(y)\n",
        "y=LeakyReLU()(y)\n",
        "y=Conv2DTranspose(filters=1,kernel_size=3,strides=1,padding='same')(y)\n",
        "y=BatchNormalization()(y)\n",
        "y=Dropout(rate=0.25)(y)\n",
        "y=Activation('sigmoid')(y)\n",
        "decoder_out=y\n",
        "de_model=Model(decoder_input,decoder_out)\n",
        "#de_model.summary()"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsTICJYAn6aw",
        "outputId": "38d7e9c8-e956-4303-f77c-6acc052d19f1"
      },
      "source": [
        "model=Model(encoder_input,de_model(encoder_out))\n",
        "model.summary()"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_22\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 28, 28, 32)   320         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 28, 28, 32)   128         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_71 (Dropout)            (None, 28, 28, 32)   0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_65 (LeakyReLU)      (None, 28, 28, 32)   0           dropout_71[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 14, 14, 32)   9248        leaky_re_lu_65[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 14, 14, 32)   128         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_72 (Dropout)            (None, 14, 14, 32)   0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_66 (LeakyReLU)      (None, 14, 14, 32)   0           dropout_72[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 16)     4624        leaky_re_lu_66[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 16)     64          conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_73 (Dropout)            (None, 7, 7, 16)     0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_67 (LeakyReLU)      (None, 7, 7, 16)     0           dropout_73[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 16)     2320        leaky_re_lu_67[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 7, 7, 16)     64          conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_74 (Dropout)            (None, 7, 7, 16)     0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_68 (LeakyReLU)      (None, 7, 7, 16)     0           dropout_74[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_11 (Flatten)            (None, 784)          0           leaky_re_lu_68[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_30 (Dense)                (None, 2)            1570        flatten_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_31 (Dense)                (None, 2)            1570        flatten_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_10 (Lambda)              (None, 2)            0           dense_30[0][0]                   \n",
            "                                                                 dense_31[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "model_21 (Functional)           (None, 28, 28, 1)    9629        lambda_10[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 29,665\n",
            "Trainable params: 29,411\n",
            "Non-trainable params: 254\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6OF05PNoOlx"
      },
      "source": [
        "optimizer=Adam(lr=0.0005)\n",
        "def squareloss(a,b):\n",
        "  return 1000*K.mean(K.square(a-b), axis = [1,2,3])\n",
        "def kl_div(a,b):\n",
        "  kl_loss = -0.5 * K.sum(1+log_var-K.square(u)-K.exp(log_var),axis = 1)\n",
        "  return kl_loss\n",
        "def loss(a,b):\n",
        "  return squareloss(a,b)+kl_div(a,b)\n",
        "model.compile(optimizer=optimizer,loss=loss,metrics=[squareloss, kl_div])"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6RdAM1Tp-BQ",
        "outputId": "c5d035eb-d0e6-47a0-eff5-d991d463f096"
      },
      "source": [
        "model.fit(x=x_train,y=x_train,batch_size=32,shuffle=True,epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/10\n",
            "29568/60000 [=============>................] - ETA: 1:45 - loss: 7220542.1521 - squareloss: 7220526.5000 - kl_div: 18.0451"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}